{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"浵通","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"同步异步阻塞非阻塞","slug":"同步异步","date":"2018-08-06T03:43:06.809Z","updated":"2018-08-06T12:41:28.207Z","comments":true,"path":"2018/08/06/同步异步/","link":"","permalink":"http://yoursite.com/2018/08/06/同步异步/","excerpt":"","text":"同步异步从分布式系统的角度分析，同步异步关注的是分布式消息通信系统，所谓同步即消息的发送者发送出消息后，需要等待消息处理后的返回结果，此时发送者发送出消息后获得的可能是空值，一部分结果，或者全部结果（取决于接收方消息处理系统的能力）；异步即消息的发送者发送完消息后，就立即返回，一定不会得到结果，而消息的处理正确性则由消息接收方去保证。可以看出同步异步关心的点在于如何去协调发送方和接收方。 从单机系统来说，同步异步关注的就是调用方和服务方是如何协调的。所谓同步就是调用方发出调用请求后，需要主动等待调用结果；而异步方式则是发出调用请求后，立即返回，接着干别的任务，而由别的线程去处理请求，请求处理结束后，将结果通知当前线程。 综上同步异步关注的一定是通信中的双方或者调用方和服务方。 阻塞非阻塞阻塞和非阻塞关注的是程序发出调用后，等待返回结果的一种状态，可以阻塞，将当前线程挂起，从运行状态切换到阻塞状态，也可以轮询等待返回结果，让线程一直处于运行状态。因此，只有在同步的模式下才谈论阻塞和非阻塞。可以看出阻塞和非阻塞关注的仅仅是发起调用的一方，而与被调用者无关。 同步异步阻塞和非阻塞用在很多场景下，因此在讨论的时候应该给出合理的上下文环境。 从五种上下文环境来谈论同步异步阻塞和非阻塞1、CPU进行IO CPU进行IO时，使用异步非阻塞方式进行IO，即发出IO请求后，并不等待IO完成，而是继续执行后续的指令，IO操作和CPU操作并行执行，IO操作完成后，通过中断方式通知CPU。 2、消息通信系统（网络的同步与异步） 一般采用异步的方式，即消息发送者发送完消息就立即返回，消息处理和结果的正确性由消息的接收方去保证。这样可以达到系统高度解耦，同时进行流量肖锋。例如天猫淘宝的消息系统，是如何可以抗住双十一的高峰流量。 3、数据刷盘 同步刷盘：当消息写入内存后，并且写入磁盘后，在将结果返回给消息的发送方异步刷盘：当消息写入内存后，立即返回，告诉消息的发送者，消息已经发送成功，然后由其他的线程将消息写入磁盘，并且保证写入磁盘的正确性。 4、IO 网络IO的本质是对Socket的读取，Socket在操作系统中被抽象为流，IO操作可以理解为对流的操作。从socket流的角度来看IO，可以分为两个阶段： 等待网络上的数据分组到达，复制到内核的某个缓冲区 把数据从内核缓冲区复制到用户进程缓冲区 Unix网络编程中给出了五种IO模型 阻塞IO模型：这是常用的IO模型，默认情况下所有的套接字都是阻塞的。recvfrom是系统调用，在应用进行发生系统调用到将数据从内核缓冲区复制到用户进程缓冲区都是阻塞的。 优点：编程简单，调试简单，单次响应时间低 缺点：需要等待 非阻塞模型：用户进程轮询内核，查看内核的数据报文是否准备好。优点：用户进程轮询期间可以干别的任务，不用仅仅处于等待状态，即当前进程可以同时处理多个任务。系统总的吞吐量增大。 缺点：导致IO任务完成的响应时间增大，因为在轮询期间进程会处理别的任务，有可能在处理别的任务期间，内核就已经将数据准备好。 IO多路复用（select poll epoll） 调用select，让其阻塞在两个系统调用（select询问数据是否准备好并且直到数据准备才返回，recvfrom 是否把数据全部复制到用户进程缓冲区，在未完成复制之前，进程一直阻塞在recvfrom函数上 ）中的某一个。 对比之前的同步非阻塞IO，Select可以同时轮询多个socket的状态，只要有socket处于可读状态，select就可以返回。然后进程在调用recvfrom将数据从内核拷贝到用户缓冲区。当然这个过程进程也处于阻塞的状态。 优点：能同时处理多个连接，不用为每个新接入的连接都分配一个线程去处理。节省系统开销。‘ 缺点：当连接的数目不多时，可能性能比不上多线程+阻塞IO。 信号驱动IO 异步IO 发起系统调用，立即返回，数据准备和数据复制都由内核完成，然后通知用户进程。 5、程序员感知到的异步同步和阻塞和非阻塞 底层接口使用会比较复杂，因此各种对底层接口封装的类库各式各样，可以选择同步的方式或者异步的方式来实现。比如node.js在程序员感知层次提供了异步非阻塞的API。","categories":[],"tags":[]},{"title":"内核空间与用户空间","slug":"内核空间与用户空间","date":"2018-08-06T02:44:28.406Z","updated":"2018-08-06T03:43:00.234Z","comments":true,"path":"2018/08/06/内核空间与用户空间/","link":"","permalink":"http://yoursite.com/2018/08/06/内核空间与用户空间/","excerpt":"","text":"内核空间与用户空间的概念：内核空间与用户空间是操作系统对物理内存在逻辑上的划分。 内核空间：存放内核代码和数据，独立于普通应用程序空间。运行在较高的特权级别上，拥有访问所有硬件设备的权限。 用户空间：存放用户进程代码和数据，只能访问到部分系统资源，不能直接访问内核空间以及硬件设备。 内核态和用户态的概念：描述的是操作系统运行的两个不同级别。 内核态：当一个进程因为触发软中断陷入内核空间执行时，那么此时进程处于内核态；（内核栈） 用户态：当一个进程在执行自己的代码时，称之处于用户态。（用户栈）","categories":[],"tags":[]},{"title":"java反射机制-动态代理","slug":"java反射机制 - 动态代理","date":"2018-08-04T16:19:34.755Z","updated":"2018-08-06T02:03:10.695Z","comments":true,"path":"2018/08/05/java反射机制 - 动态代理/","link":"","permalink":"http://yoursite.com/2018/08/05/java反射机制 - 动态代理/","excerpt":"","text":"java的设计模式-代理模式代理模式中存在两种对象：代理类 和委托类 代理模式的特点：代理类和委托类都实现相同的接口，委托类委托代理类实现一些与核心业务无关的通用业务逻辑，而自己专注处理核心的业务逻辑。例如演艺圈，艺人们都需要经纪人去代替他们和第三方洽谈档期等等事宜，而他们则专注做好表演的工作。那么经纪人就起着代理的作用。代理模式结构如图（图片来自大话设计模式）： 静态代理模式静态代理模式中的代理类是由程序员创建或者工具创建，在程序编译期间，接口、代理类和被代理类就是确定的。类比明星，静态代理模式下每位艺人都会安排固定的经纪人，不管艺人的档期的忙或闲，某个经纪人就只负责代理特定的艺人的事务。下面通过一个简单的静态代理的例子来描述静态代理 共有的接口 interface Person&#123;123 public void sing(String name);&#125; 委托类： 123456public class Star implements Person&#123; public void sing(String name) &#123; System.out.println(&quot;正在演唱：&quot;+name); &#125;&#125; 代理类： 1234567891011121314public class Proxy implements Person&#123; Star star; public Proxy(Person person) &#123; if(person.getClass()==Star.class) &#123; this.star=person; &#125; &#125; public void sing(String name) &#123; System.out.println(&quot;通知明星演唱&quot;); star.sing(name); &#125;&#125; 测试 12345678910public class StaticProxyTest&#123; public static void main(String[] args) &#123; //创建被委托对象 Star star=new Star(); //创建代理对象 Proxy proxy=new Proxy(star); proxy.sing(&quot;同一首歌&quot;); &#125;&#125; 动态代理从上述的静态代理的例子中可以得到结论：静态代理模式中的代理类在运行前必须编写好，如果需要为多个艺人代理，那就必须预先编写好所有的为每位艺人代理的代理类。这样做，成本非常高，试想一下，如果很多艺人都是三线或者四线，档期很空闲，那么他们的艺人就会无事可做，导致资源浪费。为什么不是根据当前艺人们的需求动态配置经纪人呢？因此动态代理就产生了。 动态代理模式中的代理类是在程序运行期间动态生成的。类比艺人，当某个艺人需要代理事务时，从现有的代理中查询有没有合适的经纪人可以代理此艺人的当前的事务，如果没有就为该艺人配置一个新的艺人。下面举例说明： 程序运行时动态生成代理对象 12345678910111213141516171819202122232425262728public class Proxy &#123; //即将被代理的对象 Person person; public Proxy(Person person)&#123; this.person=person; &#125; //已经被代理的对象(将被代理对象和代理对象关联) public Person getPersonProxy() &#123; ClassLoader loader=Person.class.getClassLoader(); Class[] interfaces= &#123;Person.class&#125;; InvocationHandler h=new InvocationHandler() &#123; //proxy 代理的对象 //method 被代理的对象中的方法 //参数 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;通知明星演唱：&quot;); Object o=method.invoke(person, args); return o; &#125; &#125;; Person p=(Person)Proxy.newProxyInstance(loader, interfaces, h); return p; &#125;&#125; 测试 12345678public class DynamicProxy&#123; public static void mian(String[] args) &#123; //获取代理类对象 Person p=(Person)new Proxy(new Star()).getPersonProxy(); p.sing(&quot;同一首歌&quot;); &#125;&#125; 通过上述动态代理的例子发现动态代理中的代理类是在程序运行时生成。动态代理抽象了InvocationHandler接口，对代理类代理的事务方法进行统一处理（这里用到java反射，Method.invoke（）方法执行方法调用）。我们可以很方便的在方法执行前后增加核心业务无关的业务逻辑，例如日志，验证等等，大大的减少了代码量。 简单分析newProxyInstance的过程1234567891011121314生成与指定的类加载器和一组接口相关的代理类Class cl = getProxyClass0(loader, interfaces); proxyClassCache.get(loader, interfaces); 保存已经生成的代理类，在生成代理类时，如果存在与指定类加载器和一组接口相关的代理类，则直接返回，否则生成新的代理类。 proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());通过反射获取构造函数并生成代理类实例对象final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams);cons.newInstance(new Object[]&#123;h&#125;); 12深入分析newProxyInstance的过程https://www.ibm.com/developerworks/cn/java/j-lo-proxy1/index.html","categories":[],"tags":[]},{"title":"java反射机制的基本概念","slug":"java反射机制","date":"2018-08-04T07:33:41.683Z","updated":"2018-08-05T05:34:14.242Z","comments":true,"path":"2018/08/04/java反射机制/","link":"","permalink":"http://yoursite.com/2018/08/04/java反射机制/","excerpt":"","text":"什么是java反射机制？反射这个概念用在生物学中是指在中枢神经系统的参与下，人的机体对外界环境刺激作出的规律性的反应。那么反射在java中赋予了新的含义，即程序在运行时可以动态加载编译期完全未知的类，并动态获取整个类的完整结构，从而达到运行时去动态检测类的状态并修改类的结构的目的。 从具体实现的角度来说：通过Class类，在程序运行中，可以动态获取编译期未知的类的成员变量，动态的调用类中任意的方法，获取当前对象所属的类，这种动态获取类自身的信息并进行动态改变类结构的功能就被称为java的反射机制。 java反射机制提供了哪些功能？与java发射相关的API在包java.lang.raflect中。 java反射机制最核心的类是Class 类（也可以称之为反射类，java就是通过这个反射类实现了java的反射的功能）。获取Class类的对象有三种方式： .class 每个类都隐含一个Class对象Class class=String.class 通过getClass方法String str=”java reflect”Class class=str.getClass(); 通过Class.forName(“”);Class class=Calss.forName(“java.lang.String”); Class类的方法如下： getName():获取类的完整名字 getFileds():获取类的公有属性 getDeclaredFileds():获取类的所有属性 getMethods():获取类的公有方法 getDeclaredMethods():获取类的所有方法 getMethod(String name,Class[] parameterTypes)获取指定类的指定参数列表的方法 getConstructors():获取类的公有的构造方法 getConstructor(Class[] parameterTypes):获取类特定的构造方法 newInstance():通过类的不带参数的构造方法创建这个类的一个对象； 除了上述的Class类，与反射相关的类还有如下列举的： Array类 提供动态生成和访问java数组的方法 Constructor类 提供一个类的构造函数的信息，同时提供访问一个类的构造函数的接口 Filed类 提供一个类的成员变量的信息以及访问类成员变量的接口 Method类 提供一个类的方法的信息以及访问类中的方法的接口Method.invoke() Modifiler类 提供一个类static方法和常量的信息 Proxy 提供动态生成代理类和类实例的静态方法 综上Reflect提供的API，总结出java反射机制提供的功能： 在运行时判断对象所属的类型 object.getClass==Object.class 在运行时获取类的完整信息，包括成员变量和方法，常量和静态方法 在运行时动态创建对象 class.newInstance() 在运行时调用类中任意的方法Method[] methods=getDeclaredMethods()&amp;&amp;method.invoke(Object,parameters[]) 创建动态代理实例 Proxy.newProxyInstance(classloader, interfaces, InvocationHandler)","categories":[],"tags":[]},{"title":"蘑菇街平台技术部实习收获与感悟","slug":"实习总结","date":"2018-08-04T06:32:46.662Z","updated":"2018-08-04T10:41:34.004Z","comments":true,"path":"2018/08/04/实习总结/","link":"","permalink":"http://yoursite.com/2018/08/04/实习总结/","excerpt":"","text":"知识方面：基于之前对消息中间件一些浅显的认知基础上，通过这次实习，对rocketmq和kafka的分布式消息存储机制有了更深的理解，同时也对二者的存储实现机制做了对比和性能分析。但是由于时间比较短暂，也没有机会真正的实践，后面希望自己能有机会从源码的角度去更全面的理解消息中间件产品，并能做一些思考和实践，真正去体会消息中间件产生的意义和应用的场景。 性能优化方面： 在实现一键邮件通知客户端升级的功能的过程中，有批量访问米兰服务和批量发送邮件的需求。如果仅仅是用串行来做，那么QPS和RTT都达不到预期值。二者都可以看作是远程调用，那么首先定位影响系统性能的因素在网络IO。那么解决网络IO慢的方式通常有两种：多线程和网络异步，因为console本身对性能的要求并没有那么高，而且使用console的频率也并不高，因此采用了多线程的方式来实现。那么多线程对性能的提高取决于任务的类型，即任务可以被并行执行的部分占整个任务的比重，在这里多次请求之间是完全可以并行的，还有就是线程数的设置。基于我以前的认知，我认为线程数的设置和任务的性质有关，任务是IO密集型还是CPU密集型，线程数的设置是不一样的。对于IO密集型，因为存在阻塞，那么线程数可以设置的大于处理器的逻辑核数，反之应该和逻辑核数相等。而线程数的上限应该和内存有关，因为每个线程都需要有自己的栈空间。基于上述的认识，我将核数设置成和核数相等的数，发现RTT没有丝毫变换。我想了一下原因，上述设置线程数的规则并没有错，但是是有条件的，我想只有当每个子任务没有阻塞并且负载都及其高的情况下，设置线程数和核数相等就不会有问题。所以提高了线程数到100 ，发现RTT降低了，在继续增加线程数发现RTT没有降 低反而提高了。 理论上，多线程的RTT取决于子任务最慢的那一个的RTT，那么随着线程数的增多应该不会提高。开始分析的时候，我觉得是因为线程数增多，必然会导致cs的时间增大，会不会影响RTT呢？确认CS的时间会远远小于网络传输的时间，因此做了单次RPC RTT的测试，分析出RTT无法在降低主要是因为米兰系统没有提供高并发的场景，扛不住这么高的QPS。 通过这次实习的经历，我对性能优化的问题也不再感到慌乱。衡量一个系统性能一般有两个指标 。 QPS，RTT。影响系统性能的因素大多发生在多次访存，或者磁盘，或者网络IO。对于内存，可以根据cache的特性，优化代码，提高cache命中率，减少访存次数，对于磁盘，可以增加缓存，同时尽量保证是顺序访问磁盘，对于网络IO可以通过网络异步方式提高RTT和QPS。对于网络IO瓶颈，RTT取决于调用方的RTT和远程服务处理的RTT，以及网络传输的延迟。网络传输是不可控的，那么只能从调用方做优化，但优化的同时需要考虑我们对远程服务QPS的要求，否则可能会因为对方无法承受高QPS而导致服务挂掉。 代码重构：这次代码重构可能花费将近2个星期左右的时间。我在这方面也比较欠缺，之前编码目标就是实现功能，很少考虑到代码的可重用性和可维护性。这次经历我也明白了编码的时候不仅仅要考虑功能，代码的设计同样重要。体会比较深的是对功能的高度的抽象，达到最后每一个模块都可以重用，第二就是异常的处理，第三就是编码的时候逻辑思维一定要缜密，边边角角都要考虑到。 实习的这段时间，感觉自己相比之前，从宏观上懂了很多套路，希望自己在今后的学习生，可以仔细去领悟和琢磨，能细化一些并不是理解很深的点。最后感觉学长对我毫不保留的指导，也感谢组里其他同事对我的照顾和指导。最后祝大家工作顺利，也祝公司越来越好！","categories":[],"tags":[]}]}